name: gelbooru-xpath
# for gelbooru 0.2+
# https://github.com/stashapp/CommunityScrapers/issues/2273
# loosely based on danbooru

# intended to capture filename as produced by gallery-dl (rule34_<id>_<hash>.<ext>)
sceneByFragment:
  action: scrapeXPath
  queryURL: "{filename}"
  queryURLReplace:
    filename:
      - regex: "[^a-zA-Z\\d\\-._~]" # clean filename so that it can construct a valid url
        with: ""
      - regex: "^gelbooru_(.*)" # map to domain by prefix
        with: "https://gelbooru.com/index.php?page=post&s=view&id=$1"
      - regex: "tbib_(.*)" # map to domain by prefix
        with: "https://tbib.org/index.php?page=post&s=view&id=$1"
      - regex: "^rule34_(.*)" # map to domain by prefix
        with: "https://rule34.xxx/index.php?page=post&s=view&id=$1"
      - regex: "^xbooru_(.*)" # map to domain by prefix
        with: "https://xbooru.com/post/show/$1"
      - regex: "^/safebooru_(.*)" # map to domain by prefix
        with: "https://safebooru.org/post/show/$1"
      - regex: "^/hypnohub_(.*)" # map to domain by prefix
        with: "https://hypnohub.net/post/show/$1"
      - regex: "^yandere_(.*)" # map to domain by prefix
        with: "https://yande.re/post/show/$1"
      - regex: '^(.*&id=)([0-9]+)_.*$' # capture numeric sequence at begining as ID
        with: "$1$2"
  scraper: postScraper
# intended to capture filename as produced by gallery-dl (rule34_<id>_<hash>.<ext>)
imageByFragment:
  action: scrapeXPath
  queryURL: "{filename}"
  queryURLReplace:
    filename:
      - regex: "[^a-zA-Z\\d\\-._~]" # clean filename so that it can construct a valid url
        with: ""
      - regex: "^gelbooru_(.*)" # map to domain by prefix
        with: "https://gelbooru.com/index.php?page=post&s=view&id=$1"
      - regex: "tbib_(.*)" # map to domain by prefix
        with: "https://tbib.org/index.php?page=post&s=view&id=$1"
      - regex: "^rule34_(.*)" # map to domain by prefix
        with: "https://rule34.xxx/index.php?page=post&s=view&id=$1"
      - regex: "^xbooru_(.*)" # map to domain by prefix
        with: "https://xbooru.com/post/show/$1"
      - regex: "^/safebooru_(.*)" # map to domain by prefix
        with: "https://safebooru.org/post/show/$1"
      - regex: "^/hypnohub_(.*)" # map to domain by prefix
        with: "https://hypnohub.net/post/show/$1"
      - regex: "^yandere_(.*)" # map to domain by prefix
        with: "https://yande.re/post/show/$1"
      - regex: '^(.*[^0-9])([0-9]+)_.*$' # capture numeric sequence at begining as ID
        with: "$1$2"
  scraper: postScraper

sceneByURL:
  - action: scrapeXPath
    url: &urls
      - https://gelbooru.com
      - https://tbib.org
      - https://rule34.xxx
      - https://xbooru.com
      - https://safebooru.org
      - https://hypnohub.net
      - https://yande.re/post/show/
    scraper: postScraper
imageByURL:
  - action: scrapeXPath
    url: *urls
    scraper: postScraper

xPathScrapers:
  postScraper:
    image:
      # title intentionally excluded
      #Title: &title
      #  selector: //title
      Date: &date
        selector: //div[@id="post-view" or @id="container"]//li[contains(text(),"Posted")]/text()[1]
        postProcess:
          - replace:
            - regex: 'Posted:'
              with: ""
            - regex: \d{2}:\d{2}:\d{2}$
              with: ""
          - parseDate: 2006-01-02
      Performers: &performers
        Name:
          selector: //div[@id="post-view" or @id="container"]//li[contains(@class,"tag-type-character")]/a[last()]/text()
      Studio: &artist
        Name: //div[@id="post-view" or @id="container"]//li[contains(@class,"tag-type-artist")]/a[last()]/text()
      Tags: &tag_string
        Name:
          # Variant A: only pull tags
          #selector: //div[@id="post-view" or @id="container"]//li[contains(@class,"tag-type-general")]/a[last()]/text()
          # Variant B: also pull metadata tags (like 2D, 3D, AI generated)
          selector: //div[@id="post-view" or @id="container"]//li[contains(@class,"tag-type-general") or contains(@class,"tag-type-metadata")]/a[last()]/text()
      URLs: &source
        selector: '//div[@id="post-view" or @id="container"]//li[contains(text(),"Source:")]/a/@href'
      # pulls note overlay texts (translations) into Details box
      Details:
        selector: //div[@id="post-view" or @id="container"]//div[contains(@class,"note-body")]/text()
        concat: "\n"
    scene:
      # title intentionally excluded
      #Title: *title
      Date: *date
      Performers: *performers
      Studio: *artist
      Tags: *tag_string
      URLs: *source

driver:
  headers:
    - Key: User-Agent
      Value: stashapp/stash scraper

# Last Updated October 17, 2025
